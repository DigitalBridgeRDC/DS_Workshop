{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Libraries in Python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and Feature Engineering the Data\n",
    "df.head()\n",
    "\n",
    "# Define which columns contain our features\n",
    "feature_cols = df.columns.to_list()\n",
    "\n",
    "# Discretize each column into quantiles\n",
    "for column in feature_cols:\n",
    "  df[column] = \n",
    "pd.qcut(df[column].sort_values().rank(method='first'), q=5, \n",
    "\tduplicates='raise', labels=False)  \n",
    "\n",
    "# Convert to a numpy array\n",
    "X = df[feature_cols]\n",
    "X = np.array(X)\n",
    "\n",
    "# Scale the values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality Reduction with PCA\n",
    "# Instantiate PCA\n",
    "pca = PCA(n_components=16, random_state=99).fit(X_scaled)\n",
    "\n",
    "# Store explained variance results in a DataFrame\n",
    "evar_df =  pd.DataFrame(data=pca.explained_variance_ratio_, \n",
    "\t\tindex=range(1,len(feature_cols)+1)).rename(columns={0:'pct_explained_variance'})\n",
    "\n",
    "# Calculate cumulative explained variance\n",
    "evar_df['cum_explained_variance'] = evar_df.cumsum()\n",
    "\n",
    "# Plot using matplotlib\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "ax = fig.gca()\n",
    "\n",
    "sns.lineplot(data=evar_df, x=evar_df.index, \n",
    "\t\ty='cum_explained_variance', ax=ax, color='blue').set_title('PCA Cumulative Explained Variance')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.xlabel('principal components')\n",
    "plt.xticks(evar_df.index)\n",
    "plt.ylim(0,1)\n",
    "\n",
    "for i, ev in enumerate(round(((evar_df.cum_explained_variance)*100),1).to_list()):\n",
    "    plt.text(evar_df.index[i]-.24, \n",
    "\tevar_df.cum_explained_variance[i+1]-.05, ev, color='blue')\n",
    "\n",
    "# Instantiate PCA with 10 principal components & fit to our dataset\n",
    "pca = PCA(n_components=10, random_state=99).fit(X_scaled)\n",
    "\n",
    "# Transform our dataset\n",
    "X_scaled_red = pca.transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing K-Means Clustering in Python\n",
    "\n",
    "# Instantiate KMeans class\n",
    "clusterer = KMeans(n_clusters=6, random_state=99)\n",
    "\n",
    "# Compute cluster centers and predict cluster for each sample\n",
    "cluster_labels = clusterer.fit_predict(X_scaled_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with samples and corresponding cluster labels\n",
    "cluster_df = pd.DataFrame(data=X_scaled_red, \n",
    "columns=['pc1','pc2','pc3','pc4','pc5','pc6','pc7','pc8','pc9','pc10'])\n",
    "cluster_df['cluster'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which features to plot\n",
    "feature1 = 'pc1'\n",
    "feature2 = 'pc2'\n",
    "feature3 = 'pc3'\n",
    "\n",
    "# Set up figure\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Define our custom color list\n",
    "color_list = ['deeppink', 'blue', 'forestgreen', 'orange', 'palegreen', 'darkviolet', 'moccasin', 'crimson', 'lightsteelblue', 'cyan']\n",
    "\n",
    "# Iterate over each cluster, plotting on our figure\n",
    "for i in range(cluster_df.cluster.nunique()):\n",
    "    label = \"cluster=\" + str(i)\n",
    "    ax.scatter3D(cluster_df[cluster_df.cluster==i][feature1],cluster_df[cluster_df.cluster==i][feature2], cluster_df[cluster_df.cluster==i][feature3], c=color_list[i], label=label)\n",
    "\n",
    "# Set labels and legend\n",
    "ax.set_xlabel(feature1)\n",
    "ax.set_ylabel(feature2)\n",
    "ax.set_zlabel(feature3)\n",
    "ax.set_title('Holiday Shopping KMeans Clusters')\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
